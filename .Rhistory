220-185
35 / 1.83
log(1)
log(-1)
plot(1:10, log(1:10)
)
plot(.01:10, log(1:10))
plot(.01:10, log(.01:10))
plot(seq(.001,10,.01), log(seq(.001,10,.01)))
345-318
24*1.83
185.01 + 43.92
23 / 1.83
8 / 1.83
228 / 212
228 - 212
(228 - 212) / 1.83
qclcd.2005.2015
setwd("~/Documents/Courses/Stanford 1/MachineLearning/Project/hydrodynamic-model/meteorology")
source('meteorology-util/download.qclcd.daily.R')
?save
# get the qclcd data
source('meteorology-util/download.qclcd.daily.R')
?file.exists
library("acepack", lib.loc="/Library/Frameworks/R.framework/Versions/3.2/Resources/library")
detach("package:acepack", unload=TRUE)
install.packages("a")
station.data
data.2014 = downloadload.qclcd.daily('2014', '2014', wbans=c(24149, 24243))
data.2014 = downloadload.qclcd.daily('2014', '2014', wbans=c(24149, 24243))
csv.read('200501daily.txt')
read.csv('200501daily.txt')
d = read.csv('200501daily.txt')
names(d)
d$Wind.Direction
names(d)
d = read.csv('201401daily.txt')
names(d)
downlod.file('http://www.ncdc.noaa.gov/orders/qclcd/QCLCD201401.zip')
tmp = download.file('http://www.ncdc.noaa.gov/orders/qclcd/QCLCD201401.zip')
tmp = download.file('http://www.ncdc.noaa.gov/orders/qclcd/QCLCD201401.zip', 'tmp.zip')
data.month = read.csv(unz('tmp.zip'))
data.month = read.csv(unz('tmp.zip', 'tmp.csv'))
unz('201401daily.txt', 'tmp.zip')
read.csv(unz('201401daily.txt', 'tmp.zip'))
read.csv(unz('tmp.zip','201401daily.txt'))
t2014 = read.csv(unz('tmp.zip','201401daily.txt'))
names(t2014)
data.2014 = downloadload.qclcd.daily('2014', '2014', wbans=c(24149, 24243))
library(stringr)
downloadload.qclcd.daily = function(start.year, end.year, wbans=NULL) {
url.base.new = 'http://www.ncdc.noaa.gov/orders/qclcd/QCLCDYYYYMM.zip'
url.base.old = 'http://www.ncdc.noaa.gov/orders/qclcd/YYYYMM.tar.gz'
years = start.year:end.year
data.period = NULL
for(year in years){
data.year = NULL
for(month in 1:12){
if(year < 2007 || (year == 2007 && month < 5) ){
url.base = url.base.old
type = 'old'
} else {
url.base = url.base.new
type = 'new'
}
temp <- tempfile()
date.string = paste0(year, sprintf('%.2i', month))
url = str_replace(url.base,'YYYYMM', date.string)
filename = paste0(date.string, 'daily.txt')
download.file(url,temp)
if(type == 'old'){
untar(temp, file=filename)
data.month = read.csv(filename)
data.month = data.frame(
'WBAN' = data.month$Wban.Number,
'YearMonthDay' = data.month$YearMonthDay,
'Tmax' = data.month$Max.Temp,
'Tmin' = data.month$Min.Temp,
'Tavg' = data.month$Avg.Temp,
'DewPoint' = data.month$Avg.Dew.Pt,
'WetBulb' = data.month$Avg.Wet.Bulb,
'AvgSpeed' = data.month$Wind.Avg.Speed,
'WindDirection' = data.month$Wind.Direction)
} else {
data.month = read.csv(unz(temp, filename))
data.month = data.frame(
'WBAN' = data.month$WBAN,
'YearMonthDay' = data.month$YearMonthDay,
'Tmax' = data.month$Tmax,
'Tmin' = data.month$Tmin,
'Tavg' = data.month$Tavg,
'DewPoint' = data.month$DewPoint,
'WetBulb' = data.month$WetBulb,
'AvgSpeed' = data.month$AvgSpeed,
'WindDirection' = data.month$Max2Dir)
}
unlink(temp)
data.year = rbind(data.year, data.month)
}
data.period = rbind(data.period, data.year)
}
# filter by WBAN if provided
if(!is.null(wbans)){
data.period = data.period[data.period$WBAN %in% wbans,]
}
return(data.period)
}
data.2014 = downloadload.qclcd.daily('2014', '2014', wbans=c(24149, 24243))
names(data.2014)
plot(data.2014$WindDirection)
plot(as.numeric(data.2014$WindDirection))
library(stringr)
downloadload.qclcd.daily = function(start.year, end.year, wbans=NULL) {
url.base.new = 'http://www.ncdc.noaa.gov/orders/qclcd/QCLCDYYYYMM.zip'
url.base.old = 'http://www.ncdc.noaa.gov/orders/qclcd/YYYYMM.tar.gz'
years = start.year:end.year
data.period = NULL
for(year in years){
data.year = NULL
for(month in 1:12){
if(year < 2007 || (year == 2007 && month < 5) ){
url.base = url.base.old
type = 'old'
} else {
url.base = url.base.new
type = 'new'
}
temp <- tempfile()
date.string = paste0(year, sprintf('%.2i', month))
url = str_replace(url.base,'YYYYMM', date.string)
filename = paste0(date.string, 'daily.txt')
download.file(url,temp)
if(type == 'old'){
untar(temp, file=filename)
data.month = read.csv(filename)
data.month = data.frame(
'WBAN' = data.month$Wban.Number,
'YearMonthDay' = data.month$YearMonthDay,
'Tmax' = data.month$Max.Temp,
'Tmin' = data.month$Min.Temp,
'Tavg' = data.month$Avg.Temp,
'DewPoint' = data.month$Avg.Dew.Pt,
'WetBulb' = data.month$Avg.Wet.Bulb,
'AvgSpeed' = data.month$Wind.Avg.Speed,
'WindDirection' = data.month$Wind.Direction)
} else {
data.month = read.csv(unz(temp, filename))
data.month = data.frame(
'WBAN' = data.month$WBAN,
'YearMonthDay' = data.month$YearMonthDay,
'Tmax' = data.month$Tmax,
'Tmin' = data.month$Tmin,
'Tavg' = data.month$Tavg,
'DewPoint' = data.month$DewPoint,
'WetBulb' = data.month$WetBulb,
'AvgSpeed' = data.month$AvgSpeed,
'WindDirection' = data.month$Max2Dir)
}
unlink(temp)
data.year = rbind(data.year, data.month)
}
data.period = rbind(data.period, data.year)
}
# filter by WBAN if provided
if(!is.null(wbans)){
data.period = data.period[data.period$WBAN %in% wbans,]
}
return(data.period)
}
#data.2014 = downloadload.qclcd.daily('2014', '2014', wbans=c(24149, 24243))
#data.2004 = downloadload.qclcd.daily('2004', '2004', wbans=c(24149, 24243))
#data.2007 = downloadload.qclcd.daily('2007', '2007', wbans=c(24149, 24243))
#qclcd.2005.2015 = downloadload.qclcd.daily('2005', '2015', wbans=c(24149, 24243))
#d = read.csv('201401daily.txt')
#names(d)
# get the qclcd data
source('meteorology-util/download.qclcd.daily.R')
qclcd.2005.2015 = downloadload.qclcd.daily('2005', '2016', wbans=c(24149, 24243))
save(qclcd.2005.2015, file='qclcd.2005.2015.Rdata')
# extract incident solar radiation and cloud cover from rasters
url.uswrf = 'ftp://ftp.cdc.noaa.gov/Datasets/NARR/Dailies/monolevel/uswrf.sfc.YYYY.nc'
url.clouds = 'ftp://ftp.cdc.noaa.gov/Datasets/NARR/Dailies/monolevel/tcdc.YYYY.nc'
crs.narr = '+proj=lcc +x_0=5632642.22547 +y_0=4612545.65137 +lat_0=50 +lon_0=-107 +lat_1=50 +lat_2=50 +ellps=WGS84'
station.locations = shapefile('../GIS/WeatherStationsUsed.shp')
station.locations = spTransform(station.locations, crs.narr)
crs(station.locations)
values = NULL
for(year in first.year:last.year){
download.file(str_replace(url.dswrf, 'YYYY', year), 'dswrf.nc')
uswrf.sfc = brick('uswrf.nc')
extracted.values = raster::extract(uswrf.sfc, station.locations)
if(is.null(values)){
values = extracted.values
} else {
values = cbind(values, extracted.values)
}
}
# NARR: W/m^2  (per day)
# CE-QUAL-W2: W/m^2
save(values, file='swr.2005.2015.Rdata')
swr.2005.2015 = values;
#clouds = NULL
#for(year in first.year:last.year){
#  download.file(str_replace(url.clouds, 'YYYY', year), 'clouds.nc')
#  clouds.narr = brick('clouds.nc')
#  extracted.values = raster::extract(clouds.narr, station.locations)
#  if(is.null(clouds)){
#    clouds = extracted.values
#  } else {
#    clouds = cbind(clouds, extracted.values)
#  }
#}
#save(clouds, file='clouds.2005.2015.Rdata')
qclcd.2005.2015
advection.df
write.csv(advection.df, 'Advection.2005.2015.csv')
discharges.usgs
nrow(discharges.usgs)
# Get flow from USGS
library('waterData')
library('plyr')
library('dataRetrieval')
library('lubridate')
install.packages("dataRetrieval")
install.packages("waterData")
library('plyr')
library('dataRetrieval')
library('lubridate')
install.packages("dataRetrieval")
install.packages("xml2")
devtools::install_github("hadley/xml2")
install.packages("devtools")
install.packages("git2r")
install.packages("git2r")
library('dataRetrieval')
install.packages("dataRetrieval")
devtools::install_github("hadley/xml2")
install.packages("devtools")
devtools::install_github("hadley/xml2")
library('waterData')
install.packages("waterData")
library('waterData')
library('plyr')
library('dataRetrieval')
install.packages("dataRetrieval")
library('lubridate')
library('dataRetrieval')
gauges = c(
#
# Clearwater
#
'13340000', #CLEARWATER RIVER AT OROFINO ID                       1930-10-01 	2016-08-29
# NF Clearwater at Ahsahka '13341000',   NO DISCHARGE, use DWO outflow
#
# Snake
#
'13334300', #SNAKE RIVER NEAR ANATONE, WA                         1958-07-22   2016-08-29
'13344500', #TUCANNON RIVER NEAR STARBUCK, WA  - NO TEMP          1914-10-01   2016-08-29
'13351000', #PALOUSE RIVER AT HOOPER, WA       - NO TEMP          1897-10-01   2016-08-29
#
# Columbia
#
# Grand Coulee Downstream from DART
'12447200', # Okanogan                                            1965-12-18   2016-08-29
'12449950', # Methow                                              1959-04-01   2016-08-29
'12452500', # Chelan SPILLWAY - NO TEMP                           1903-11-01   2015-09-30   * Rocky Reach minus Wells ?
'12462500', # Wenatchee - NO TEMP                                 1959-02-12   2016-05-31
'12472600', # Crab Creek CRAB CREEK NEAR BEVERLY                  1959-02-12   2016-05-31
'12510500', # Yakima - NO TEMP                                    1905-10-01   2016-08-29
'14018500', # Walla Walla - NO TEMP                               1951-10-01   2016-08-29
'14048000', # John Day  - NO TEMP                                 1904-12-01   2016-08-29
'14103000' # Deschutes                                            1897-10-01   2016-08-29
)
syear = '2005'
eyear = '2015'
sdate = paste0(syear, "-01-01")
edate = paste0(eyear, "-12-31")
discharges = c()
for(i in 1:length(gauges)){
data = importDVs(gauges[i],code="00060", sdate=sdate, edate=edate)
# should check registration of dates, but appears to be OK for current domain
print(nrow(data))
#plotParam(data)
val = na.interp(data$val)
length(val) = 4017   # THIS IS A HACK to make Chelan the right size and avoid looping
val = na.locf(val)
val = na.locf(val, fromLast = TRUE)
discharges = cbind(discharges, val)
}
discharges.usgs = as.data.frame(discharges)
names(discharges.usgs) = gauges
library('forecast')
syear = '2005'
eyear = '2015'
sdate = paste0(syear, "-01-01")
edate = paste0(eyear, "-12-31")
discharges = c()
for(i in 1:length(gauges)){
data = importDVs(gauges[i],code="00060", sdate=sdate, edate=edate)
# should check registration of dates, but appears to be OK for current domain
print(nrow(data))
#plotParam(data)
val = na.interp(data$val)
length(val) = 4017   # THIS IS A HACK to make Chelan the right size and avoid looping
val = na.locf(val)
val = na.locf(val, fromLast = TRUE)
discharges = cbind(discharges, val)
}
discharges.usgs = as.data.frame(discharges)
names(discharges.usgs) = gauges
projects = c('DWR', 'GCGW')
discharges.dams = NULL
for(project in projects){
data = download.dart.daily(project, syear, eyear)
data$Outflow..kcfs = as.numeric(data$Outflow..kcfs) *1000
# Fill/Interp Here
if(is.null(discharges.dams)){
discharges.dams = data$Outflow..kcfs
} else {
discharges.dams = cbind(discharges.dams, data$Outflow..kcfs)
}
}
discharges.dams = as.data.frame(discharges.dams)
names(discharges.dams) = projects
library('stringr')
projects = c('DWR', 'GCGW')
discharges.dams = NULL
for(project in projects){
data = download.dart.daily(project, syear, eyear)
data$Outflow..kcfs = as.numeric(data$Outflow..kcfs) *1000
# Fill/Interp Here
if(is.null(discharges.dams)){
discharges.dams = data$Outflow..kcfs
} else {
discharges.dams = cbind(discharges.dams, data$Outflow..kcfs)
}
}
discharges.dams = as.data.frame(discharges.dams)
names(discharges.dams) = projects
library('xts')
projects = c('DWR', 'GCGW')
discharges.dams = NULL
for(project in projects){
data = download.dart.daily(project, syear, eyear)
data$Outflow..kcfs = as.numeric(data$Outflow..kcfs) *1000
# Fill/Interp Here
if(is.null(discharges.dams)){
discharges.dams = data$Outflow..kcfs
} else {
discharges.dams = cbind(discharges.dams, data$Outflow..kcfs)
}
}
discharges.dams = as.data.frame(discharges.dams)
names(discharges.dams) = projects
coeffs.df = read.csv('WaterTemperatureApproximationCoefficients.csv')
approximate.stream.temperature.calc = function(coeffs.df, air.temperature.limb){
T.stream = coeffs.df$mu + (coeffs.df$alpha - coeffs.df$mu) / (1 + exp( coeffs.df$gamma * ( coeffs.df$beta - air.temperature.limb)))
return(T.stream)
}
approximate.stream.temperature = function(coeffs.df, data){
coeffs.df.rising = coeffs.df[coeffs.df$limb == 'rising',]
coeffs.df.falling = coeffs.df[coeffs.df$limb == 'falling',]
air.temperature.rising = data$AirTemperature[data$Julian < coeffs.df.falling$start]
air.temperature.falling = data$AirTemperature[data$Julian >= coeffs.df.falling$start]
T.stream.rising = approximate.stream.temperature.calc(coeffs.df.rising, air.temperature.rising)
T.stream.falling = approximate.stream.temperature.calc(coeffs.df.falling, air.temperature.falling)
T.stream = c(T.stream.rising, T.stream.falling)
return(T.stream)
}
lewiston = read.table('2005.2015/LEWISTON.HOT', header=FALSE, skip=4)
names(lewiston)=c('Julian', 'Solar', 'Atomospheric', 'AirTemperature', 'Wind', 'Bowen', 'VaporPressure', 'PhotoPeriod')
yakima = read.table('2005.2015/YAKIMA.HOT', header=FALSE, skip=4)
names(yakima)=c('Julian', 'Solar', 'Atomospheric', 'AirTemperature', 'Wind', 'Bowen', 'VaporPressure', 'PhotoPeriod')
wenatchee = read.table('2005.2015/WNATCHEE.HOT', header=FALSE, skip=4)
names(wenatchee)=c('Julian', 'Solar', 'Atomospheric', 'AirTemperature', 'Wind', 'Bowen', 'VaporPressure', 'PhotoPeriod')
stations.data = list(Lewiston = lewiston, Yakima = yakima, Wenatchee = wenatchee)
streams = c('Methow', 'Tucannon', 'John Day', 'Palouse', 'Walla Walla', 'Chelan', 'Wenatchee', 'Crab Creek', 'Yakima')
stations = c('Wenatchee', 'Lewiston', 'Lewiston', 'Yakima', 'Yakima', 'Wenatchee', 'Wenatchee', 'Wenatchee', 'Yakima')
T.streams.approx = c()
for(i in 1:length(streams)){
T.stream.approx = approximate.stream.temperature(coeffs.df[coeffs.df$site==streams[i],],
stations.data[[stations[i]]])
T.streams.approx = cbind(T.streams.approx, T.stream.approx)
}
df.approx.T = data.frame(T.streams.approx)
names(df.approx.T) = streams
lewiston = read.table('2005.2015/LEWISTON.HOT', header=FALSE, skip=4)
lewiston = read.table('2005.2015/LEWISTON.HOT', header=FALSE, skip=4)
names(lewiston)=c('Julian', 'Solar', 'Atomospheric', 'AirTemperature', 'Wind', 'Bowen', 'VaporPressure', 'PhotoPeriod')
yakima = read.table('2005.2015/YAKIMA.HOT', header=FALSE, skip=4)
names(yakima)=c('Julian', 'Solar', 'Atomospheric', 'AirTemperature', 'Wind', 'Bowen', 'VaporPressure', 'PhotoPeriod')
wenatchee = read.table('2005.2015/WNATCHEE.HOT', header=FALSE, skip=4)
names(wenatchee)=c('Julian', 'Solar', 'Atomospheric', 'AirTemperature', 'Wind', 'Bowen', 'VaporPressure', 'PhotoPeriod')
stations.data = list(Lewiston = lewiston, Yakima = yakima, Wenatchee = wenatchee)
streams = c('Methow', 'Tucannon', 'John Day', 'Palouse', 'Walla Walla', 'Chelan', 'Wenatchee', 'Crab Creek', 'Yakima')
stations = c('Wenatchee', 'Lewiston', 'Lewiston', 'Yakima', 'Yakima', 'Wenatchee', 'Wenatchee', 'Wenatchee', 'Yakima')
T.streams.approx = c()
for(i in 1:length(streams)){
T.stream.approx = approximate.stream.temperature(coeffs.df[coeffs.df$site==streams[i],],
stations.data[[stations[i]]])
T.streams.approx = cbind(T.streams.approx, T.stream.approx)
}
df.approx.T = data.frame(T.streams.approx)
names(df.approx.T) = streams
temperature.gauges = temperature.gauges[temperature.gauges != '13341000'] # North Fork not in the API
temperatures.usgs = c()
for(i in 1:length(temperature.gauges)){
data = importDVs(temperature.gauges[i],code="00010", sdate=sdate, edate=edate)
plotParam(data)
ts = xts(data$val, order.by=data$dates)
#
#  GUESS WHAT??? Need to fill missing values..
#
#   full <- seq(start, by="15 min", length=(365+365+366+365+365+365)*24*4)
#  seq.POSIXt
ts.full = xts( order.by = seq(ISOdate(2005,1,1, 0, 0, 0), ISOdate(2015,12,31, 0, 0, 0), "1 day") )
ts = merge(ts.full, ts)
ts = na.locf(ts)
ts = na.locf(ts, fromLast = TRUE)
names(ts) = 'Temperature'
ts = na.approx(ts)
temperatures.usgs = cbind(temperatures.usgs, as.numeric(ts$Temperature))
}
temperatures.usgs = data.frame(temperatures.usgs)
names(temperatures.usgs) = temperature.gauges
uv <- readNWISuv(siteNumbers = '13341000',
parameterCd = "00010",
startDate = sdate,
endDate = edate)
ts.uv.1 = xts(uv$X_00010_00011, order.by=uv$dateTime)
ts.uv.1 = ts.uv.1['2010-01-01/2015-12-31']
names(ts.uv.1) = c('WaterTemperature')
start = as.POSIXct(paste0(sdate, ' 00:15:00'),tz='UTC')
ts.full = xts( order.by = seq(ISOdate(2010,1,1, 0, 0, 0), ISOdate(2015,12,31, 0, 0, 0), "15 mins") )
ts.uv = merge(ts.full, ts.uv.1)
ts.uv = na.locf(ts.uv)
ts.uv = na.locf(ts.uv, fromLast=TRUE)
â‰ˆ = na.approx(ts.uv$WaterTemperature)
ts.uv$Julian = .indexday(ts.uv)
df.uv = as.data.frame(ts.uv)
daily.water.temperature = ddply(df.uv, c('Julian'), summarize,
WaterTemperature=mean(WaterTemperature)
)
daily.water.temperature
data = download.dart.daily('DWR', 2005, 2009)
data.temperature.2005.2009 = as.numeric(data$Temperature..C.)
data.temperature.all = append(data.temperature.2005.2009, daily.water.temperature$WaterTemperature)
temperatures.usgs$"13341000" = data.temperature.all
projects = c('GCGW')
temperatures.dams = NULL
for(project in projects) {
data = download.dart.daily(project, syear, eyear)
if(is.null(discharges.dams)){
temperatures.dams = as.numeric(data$Temperature..C.)
} else {
temperatures.dams = cbind(temperatures.dams, as.numeric(data$Temperature..C.))
}
}
temperatures.dams = as.data.frame(temperatures.dams)
names(temperatures.dams) = projects
advection.df = data.frame(
Clearwater = discharges.usgs$"13340000",
Clearwater.T = temperatures.usgs$"13340000",
Snake = discharges.usgs$"13334300",
Snake.T = temperatures.usgs$"13334300",
Columbia = discharges.dams$GCGW,
Columbia.T = temperatures.dams$GCGW,
NFClearwater = discharges.dams$DWR,
NFClearwater.T = temperatures.usgs$"13341000",
Potlatch = 62.2,
Potlatch.T = 33,
Tucannon = discharges.usgs$"13344500",
Tucannon.T = df.approx.T$Tucannon,
Palouse = discharges.usgs$"13351000",
Palouse.T = df.approx.T$Palouse,
Okanogan = discharges.usgs$"12447200",
Okanogan.T = temperatures.usgs$"12447200",
Methow = discharges.usgs$"12449950",
Methow.T = df.approx.T$Methow,
Chelan = discharges.usgs$"12452500",
Chelan.T = df.approx.T$Chelan,
Wenatchee = discharges.usgs$"12462500",
Wenatchee.T = df.approx.T$Wenatchee,
Crab = discharges.usgs$"12472600",
Crab.T = df.approx.T$"Crab Creek",
Yakima = discharges.usgs$"12510500",
Yakima.T = df.approx.T$Yakima,
WallaWalla = discharges.usgs$"14018500",
WallaWalla.T = df.approx.T$"Walla Walla",
JohnDay = discharges.usgs$"14048000",
JohnDay.T = df.approx.T$"John Day",
Deschutes = discharges.usgs$"14103000",
Deschutes.T = temperatures.usgs$"14103000"
)
advection.df =round(advection.df, digits=2)
write.csv(advection.df, 'Advection.2005.2015.csv')
20.3/61.3
year
year = 2005
year = 2005
url = 'http://www.cbr.washington.edu/dart/cs/php/rpt/river_daily.php?sc=1&outputFormat=csv&year=YYYY&proj=PROJECT&span=no&startdate=1%2F1&enddate=12%2F31'
project = 'LGNW'
url1 = str_replace(url, 'YYYY', year)
url1 = str_replace(url1, 'PROJECT', project)
library(stringr)
url1 = str_replace(url, 'YYYY', year)
url1 = str_replace(url1, 'PROJECT', project)
print(url1)
data = read.csv(url1, stringsAsFactors=FALSE)
data = data[data$Date != "",]
names(data)
names(discharges)
